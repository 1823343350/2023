{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..') \n",
    "from typing import Any\n",
    "import cupy as cp\n",
    "import torch\n",
    "\n",
    "from Deep_gpu import MyModel\n",
    "from Deep_gpu import ReLU\n",
    "from Deep_gpu import MeanSquaredError, CrossEntropyLoss\n",
    "from Deep_gpu import GradientDescentOptimizer\n",
    "from Deep_gpu import Regularization\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "多层感知机进行MINIST手写数据集的识别\n",
    "\"\"\"\n",
    "photo_nums = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# 获取MNIST数据集\n",
    "# windows\n",
    "# train_dataset = datasets.MNIST(root='G:\\学习文件\\python学习\\CODE\\data', train=True, transform=transform, download=True)\n",
    "# test_dataset = datasets.MNIST(root='G:\\学习文件\\python学习\\CODE\\data', train=False, transform=transform, download=True)\n",
    "# linux\n",
    "train_dataset = datasets.MNIST(root='/media/xc/学习/学习文件/python学习/CODE/data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='/media/xc/学习/学习文件/python学习/CODE/data', train=False, transform=transform, download=True)\n",
    "\n",
    "# 定义数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=photo_nums, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=photo_nums, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "reg = Regularization(0.001)\n",
    "\n",
    "layer_dict = {\n",
    "    'first': {\n",
    "        'type': 'conv',\n",
    "        'name': 'conv1',\n",
    "        'in_channels': 3,\n",
    "        'out_channels': 64,\n",
    "        'kernel_size': 3, # 卷积核大小\n",
    "        'stride': 1, # 步长\n",
    "        'padding': 0,# 填充\n",
    "        'activation': \"ReLU\"\n",
    "    },\n",
    "    'second': {\n",
    "        'type': 'pool',\n",
    "        'name': 'pool1',\n",
    "        'kernel_size': 2,\n",
    "        'stride': 1, # 步长\n",
    "        'pool_function': 'Max',\n",
    "    },\n",
    "    'first2': {\n",
    "        'type': 'conv',\n",
    "        'name': 'conv2',\n",
    "        'in_channels': 64,\n",
    "        'out_channels': 64,\n",
    "        'kernel_size': 2, # 卷积核大小\n",
    "        'stride': 1, # 步长\n",
    "        'padding': 0,# 填充\n",
    "        'activation': \"ReLU\"\n",
    "    },\n",
    "    'second2': {\n",
    "        'type': 'pool',\n",
    "        'name': 'pool2',\n",
    "        'kernel_size': 2,\n",
    "        'stride': 1, # 步长\n",
    "        'pool_function': 'Max',\n",
    "    },\n",
    "    'first3': {\n",
    "        'type': 'conv',\n",
    "        'name': 'conv2',\n",
    "        'in_channels': 64,\n",
    "        'out_channels': 64,\n",
    "        'kernel_size': 2, # 卷积核大小\n",
    "        'stride': 1, # 步长\n",
    "        'padding': 0,# 填充\n",
    "        'activation': \"ReLU\",\n",
    "    },\n",
    "    'second3': {\n",
    "        'type': 'flatten',\n",
    "        'name': 'flatten',\n",
    "    },\n",
    "    'output': {\n",
    "        'type': 'linear',\n",
    "        'name': 'linear1',\n",
    "        'input_features_nums': 484,\n",
    "        'Number_of_neurons': 10,\n",
    "        'activation': \"Softmax\",\n",
    "        'loss_fn': loss_fn\n",
    "    }\n",
    "}\n",
    "\n",
    "op = GradientDescentOptimizer(lr=0.001, max_iterations=1)\n",
    "model = MyModel(layers_dict=layer_dict, optimizer = op, regularization=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 photos, Epoch 1, Loss: 21.909037110287763\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    k = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "\n",
    "        x = inputs.numpy()\n",
    "        y = labels.numpy()\n",
    "        x = x.reshape(photo_nums, 28, 28)\n",
    "        x = cp.asarray(x)\n",
    "\n",
    "        y_one_hot = cp.zeros((len(y), 10))\n",
    "        for i in range(len(y)):\n",
    "            y_one_hot[i, y[i]] = 1\n",
    "\n",
    "        model.fit(x, y_one_hot)\n",
    "\n",
    "        k += 1\n",
    "        if k >= 1:\n",
    "            break\n",
    "    running_loss = model.loss[-1]\n",
    "    print(f\"{64*500} photos, Epoch {epoch + 1}, Loss: {running_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
