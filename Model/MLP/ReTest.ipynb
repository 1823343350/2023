{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..') \n",
    "from typing import Any\n",
    "import cupy as cp\n",
    "import torch\n",
    "\n",
    "from Deep_gpu import MyModel\n",
    "from Deep_gpu import ReLU\n",
    "from Deep_gpu import MeanSquaredError, CrossEntropyLoss\n",
    "from Deep_gpu import GradientDescentOptimizer\n",
    "from Deep_gpu import Regularization\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "多层感知机进行MINIST手写数据集的识别\n",
    "\"\"\"\n",
    "photo_nums = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# 获取MNIST数据集\n",
    "# windows\n",
    "# train_dataset = datasets.MNIST(root='G:\\学习文件\\python学习\\CODE\\data', train=True, transform=transform, download=True)\n",
    "# test_dataset = datasets.MNIST(root='G:\\学习文件\\python学习\\CODE\\data', train=False, transform=transform, download=True)\n",
    "# linux\n",
    "train_dataset = datasets.MNIST(root='/media/xc/学习/学习文件/python学习/CODE/data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='/media/xc/学习/学习文件/python学习/CODE/data', train=False, transform=transform, download=True)\n",
    "\n",
    "# 定义数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=photo_nums, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=photo_nums, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "reg = Regularization(0.001)\n",
    "\n",
    "layer_dict = {\n",
    "    'first': {\n",
    "        'type': 'linear',\n",
    "        'in_features': 784,\n",
    "        'out_features': 128,\n",
    "        'activation': \"ReLU\"\n",
    "    },\n",
    "    'output': {\n",
    "        'type': 'linear',\n",
    "        'in_features': 128,\n",
    "        'out_features': 10,\n",
    "        'activation': \"Softmax\",\n",
    "        'loss_fn': loss_fn\n",
    "    }\n",
    "}\n",
    "\n",
    "op = GradientDescentOptimizer(lr=0.001, max_iterations=1)\n",
    "model = MyModel(layers_dict=layer_dict, optimizer = op, regularization=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000 photos, Epoch 1, Loss: 9.352265797073656\n",
      "32000 photos, Epoch 2, Loss: 6.508026673538154\n",
      "32000 photos, Epoch 3, Loss: 6.588470234581495\n",
      "32000 photos, Epoch 4, Loss: 5.802239805325227\n",
      "32000 photos, Epoch 5, Loss: 4.801913083784061\n",
      "32000 photos, Epoch 6, Loss: 4.156478678756235\n",
      "32000 photos, Epoch 7, Loss: 5.06568730979461\n",
      "32000 photos, Epoch 8, Loss: 4.14465330464245\n",
      "32000 photos, Epoch 9, Loss: 2.3025850929940455\n",
      "32000 photos, Epoch 10, Loss: 2.7631021115928545\n",
      "32000 photos, Epoch 11, Loss: 1.3815510557964275\n",
      "32000 photos, Epoch 12, Loss: 4.605170185988091\n",
      "32000 photos, Epoch 13, Loss: 1.8420680743952365\n",
      "32000 photos, Epoch 14, Loss: 3.684136148790473\n",
      "32000 photos, Epoch 15, Loss: 0.9210340371976182\n",
      "32000 photos, Epoch 16, Loss: 2.7631021115928545\n",
      "32000 photos, Epoch 17, Loss: 0.0\n",
      "32000 photos, Epoch 18, Loss: 0.4605170185988091\n",
      "32000 photos, Epoch 19, Loss: 1.3815510557964275\n",
      "32000 photos, Epoch 20, Loss: 2.3025850929940455\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    k = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "\n",
    "        x = inputs.numpy()\n",
    "        y = labels.numpy()\n",
    "        x = x.reshape(photo_nums, -1)\n",
    "        x = cp.asarray(x)\n",
    "        y_one_hot = cp.zeros((len(y), 10))\n",
    "        for i in range(len(y)):\n",
    "            y_one_hot[i, y[i]] = 1\n",
    "\n",
    "        if x.shape[1] == 784:\n",
    "            model.fit(x, y_one_hot)\n",
    "\n",
    "        k += 1\n",
    "        if k >= 500:\n",
    "            break\n",
    "    running_loss = model.loss[-1]\n",
    "    print(f\"{64*500} photos, Epoch {epoch + 1}, Loss: {running_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9185697115384616, test_loss: 2.30258509299404\n"
     ]
    }
   ],
   "source": [
    "acc = 0.0\n",
    "current = 0.0\n",
    "loss = 0.0\n",
    "n = 0\n",
    "for batch in test_loader:\n",
    "    inputs, labels = batch\n",
    "\n",
    "    x = inputs.numpy()\n",
    "    y = labels.numpy()\n",
    "    x = cp.asarray(x)\n",
    "    y = cp.asarray(y)\n",
    "    x = x.reshape(photo_nums, -1)\n",
    "\n",
    "    if x.shape[1] == 784:\n",
    "        predict = model.predict(x)\n",
    "        loss += model.loss[-1]\n",
    "        n += 1\n",
    "        max_indices = predict.argmax(axis=0)  # 沿着列的方向找到最大值的索引, 代表模型预测的分类\n",
    "        acc = cp.sum(max_indices == y) / predict.shape[1]\n",
    "        current += acc\n",
    "\n",
    "print(f\"test_acc: {current/n}, test_loss: {loss/n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
