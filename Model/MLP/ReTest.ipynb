{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..') \n",
    "from typing import Any\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from Deep import MyModel\n",
    "from Deep import ReLU\n",
    "from Deep import MeanSquaredError, CrossEntropyLoss\n",
    "from Deep import GradientDescentOptimizer\n",
    "from Deep import Regularization\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "多层感知机进行MINIST手写数据集的识别\n",
    "\"\"\"\n",
    "photo_nums = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# 获取MNIST数据集\n",
    "# windows\n",
    "train_dataset = datasets.MNIST(root='G:\\学习文件\\python学习\\CODE\\data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='G:\\学习文件\\python学习\\CODE\\data', train=False, transform=transform, download=True)\n",
    "# linux\n",
    "# train_dataset = datasets.MNIST(root='/media/xc/学习/学习文件/python学习/CODE/data', train=True, transform=transform, download=True)\n",
    "# test_dataset = datasets.MNIST(root='/media/xc/学习/学习文件/python学习/CODE/data', train=False, transform=transform, download=True)\n",
    "\n",
    "# 定义数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=photo_nums, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=photo_nums, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CrossEntropyLoss()\n",
    "reg = Regularization(0.001)\n",
    "\n",
    "layer_dict = {\n",
    "    'first': {\n",
    "        'type': 'linear',\n",
    "        'input_features_nums': 784,\n",
    "        'Number_of_neurons': 128,\n",
    "        'activation': \"ReLU\"\n",
    "    },\n",
    "    'output': {\n",
    "        'type': 'linear',\n",
    "        'input_features_nums': 128,\n",
    "        'Number_of_neurons': 10,\n",
    "        'activation': \"Softmax\",\n",
    "        'loss_fn': loss_fn\n",
    "    }\n",
    "}\n",
    "\n",
    "op = GradientDescentOptimizer(lr=0.001, max_iterations=1)\n",
    "model = MyModel(layers_dict=layer_dict, optimizer = op, regularization=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 photos, Epoch 1, Loss: 19.98915691410225\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    k = 0\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "\n",
    "        x = inputs.numpy()\n",
    "        y = labels.numpy()\n",
    "        x = x.reshape(photo_nums, -1)\n",
    "        x = np.asarray(x)\n",
    "        y_one_hot = np.zeros((len(y), 10))\n",
    "        for i in range(len(y)):\n",
    "            y_one_hot[i, y[i]] = 1\n",
    "\n",
    "        if x.shape[1] == 784:\n",
    "            model.fit(x, y_one_hot)\n",
    "\n",
    "        k += 1\n",
    "        if k >= 1:\n",
    "            break\n",
    "    running_loss = model.loss[-1]\n",
    "    print(f\"{64*100} photos, Epoch {epoch + 1}, Loss: {running_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.07221554487179487, test_loss: 19.98915691410229\n"
     ]
    }
   ],
   "source": [
    "acc = 0.0\n",
    "current = 0.0\n",
    "loss = 0.0\n",
    "n = 0\n",
    "for batch in test_loader:\n",
    "    inputs, labels = batch\n",
    "\n",
    "    x = inputs.numpy()\n",
    "    y = labels.numpy()\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    x = x.reshape(photo_nums, -1)\n",
    "\n",
    "    if x.shape[1] == 784:\n",
    "        predict = model.predict(x)\n",
    "        loss += model.loss[-1]\n",
    "        n += 1\n",
    "        max_indices = predict.argmax(axis=0)  # 沿着列的方向找到最大值的索引, 代表模型预测的分类\n",
    "        acc = np.sum(max_indices == y) / predict.shape[1]\n",
    "        current += acc\n",
    "\n",
    "print(f\"test_acc: {current/n}, test_loss: {loss/n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
